{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Example on how this framework works\n",
    "This is just a simple example to show how you should use the experimentation code.\n",
    "The experiments used in the nCOBRAS paper are in the experiments package.\n",
    "\n",
    "## Set-up\n",
    "First of all you should fill the HOMEDIR in `config.py`.\n",
    "If you want to compare with COSC and MPCK-means you also have to fill in the WEKA_PATH and COSC_PATH.\n",
    "\n",
    "### Additional requirements for MPCK-means\n",
    "In order to run MPCK-means you will need WEKA.\n",
    "In `config.py` fill in the WEKA_PATH (root directory where weka is installed).\n",
    "You will also need a compatible version of java installed.\n",
    "\n",
    "### Additional requirements for COSC\n",
    "In order to compare with COSC you need to download COSC from:\n",
    "In `config.py` fill in COSC_PATH (the root directory where COSC is installed).\n",
    "You will also need to have matlab and matlab engine installed for python.\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module path of dont_know added\n",
      "module path of testing added\n",
      "module path of noise robust added\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path_dont_know = os.path.abspath(os.path.join('../COBRAS_dont_know'))\n",
    "module_path_testing = os.path.abspath(os.path.join('../COBRAS_testing'))\n",
    "module_path_noise_robust = os.path.abspath(os.path.join('../noise_robust_cobras'))\n",
    "if module_path_dont_know not in sys.path:\n",
    "    sys.path.append(module_path_dont_know)\n",
    "    print(\"module path of dont_know added\")\n",
    "\n",
    "if module_path_testing not in sys.path:\n",
    "    sys.path.append(module_path_testing)\n",
    "    print(\"module path of testing added\")\n",
    "    \n",
    "if module_path_noise_robust not in sys.path:\n",
    "    sys.path.append(module_path_noise_robust)\n",
    "    print(\"module path of noise robust added\")\n",
    "    \n",
    "import copy\n",
    "from pathlib import Path\n",
    "from distributed import Client, LocalCluster\n",
    "from datasets import Dataset\n",
    "from evaluate_clusterings.calculate_aligned_rank import calculate_and_write_aligned_rank\n",
    "from evaluate_clusterings.calculate_aris import calculate_n_times_n_fold_aris_for_testnames\n",
    "from evaluate_clusterings.calculate_average_aris import calculate_average_aris\n",
    "from generate_clusterings.clustering_task import ClusteringTask, make_n_run_10_fold_cross_validation\n",
    "from noise_robust_cobras.querier.noisy_labelquerier import ProbabilisticNoisyQuerier\n",
    "from noise_robust_cobras.cobras import COBRAS\n",
    "from config import HOMEDIR, FIGURE_DIR, FOLD_RESULT_DIR\n",
    "from noise_robust_cobras.strategies.splitlevel_estimation import StandardSplitLevelEstimationStrategy\n",
    "from noise_robust_cobras.strategies.superinstance_selection import LeastInstancesSelectionHeuristic\n",
    "from present_results.plot_aligned_rank import plot_rank_comparison_file\n",
    "from present_results.plot_aris import plot_average_ARI_per_dataset, plot_overall_average_ARI\n",
    "from run_with_dask.run_with_dask import execute_list_of_clustering_tasks\n",
    "from before_clustering.generate_folds import generate_folds_for_dataset\n",
    "from run_locally.run_tests import run_clustering_tasks_locally\n",
    "TEST_PATH = Path(HOMEDIR)/\"example_notebook_results\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Generate folds\n",
    "Before running any experiments you have to generate the test/training sets for all datasets\n",
    "(you only have to do this once after you do this the folds are stored on disk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if not Path(FOLD_RESULT_DIR).exists():\n",
    "     generate_folds_for_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Set-up experiments\n",
    "### Using ClusteringTask directly\n",
    "So essentially the system works by initialising `ClusteringTask` instances for each clustering operation that you want to execute.\n",
    "To initialise a clustering task you need to pass all the things necessary to execute a single clustering experiment:\n",
    "- a clusterer: a clustering algorithm (e.g. COBRAS, COSCMatlab, MPCKMeansJava, your own clusterer)\n",
    "- a dataset_name this is assumed to be a dataset that is readeable by the `Dataset` class in `dataset.py`\n",
    "- training indices: the training indices for this experiment\n",
    "- extra_result_extractor: if you want custom results to be extracted from the clusterer after clustering you can pass a result extractor (a function with signature f(clusterer): Dict)\n",
    "- querier: the querier that needs to be used for this clustering experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "data = Dataset('iris')\n",
    "clusterer = COBRAS()\n",
    "\n",
    "# labels are filled in when the clustering task is ran\n",
    "querier = ProbabilisticNoisyQuerier(None, None, 0.10, 100,random_seed=123)\n",
    "\n",
    "task = ClusteringTask(clusterer, data.name, None, None, querier, TEST_PATH/ 'example_COBRAS_run')\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A ClusteringTask can be run seperately individually.\n",
    "Usually you will not execute clustering tasks like this. You can execute a collection of clustering tasks through dask.\n",
    "This way you can easily be executed in parallel over the cores of your local machine or over different hosts through ssh.\n",
    "This will be illustrated later in this notebook.\n",
    "\n",
    "**note:** the dataset argument is to be able to run a clusteringtask easily through DASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "task.run(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Constructing n times 10 fold cross validation experiments\n",
    "If you want to execute n times 10 fold cross validation tests. You don't have to construct all clustering tasks individually.\n",
    "The make_n_run_10_fold_cross_validation function does this all for you.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "robust_clusterer = COBRAS()\n",
    "querier = ProbabilisticNoisyQuerier(None, None, 0.10, 50)\n",
    "test_name_robust = \"example_ncobras\"\n",
    "# only use 3 datasets\n",
    "all_dataset_names = ['iris'] #, 'ecoli', 'glass'\n",
    "clustering_tasks = make_n_run_10_fold_cross_validation(test_name_robust, robust_clusterer, querier, all_dataset_names, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison let's also run COBRAS with no noise correction mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clusterer = COBRAS(correct_noise=False)\n",
    "test_name = 'example_cobras'\n",
    "clustering_tasks.extend(make_n_run_10_fold_cross_validation(test_name, clusterer, querier, all_dataset_names, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To execute these tasks you can use Dask:\n",
    "(for documentation on how to set up dask over different hosts: https://docs.dask.org/en/latest/setup.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# a local dask client\n",
    "#with Client(LocalCluster(n_workers = 2)) as client:\n",
    "    # this executes all clustering tasks using the given client\n",
    "    #execute_list_of_clustering_tasks(client, clustering_tasks)\n",
    "    #execute_list_of_clustering_tasks(clustering_tasks)\n",
    "run_clustering_tasks_locally(clustering_tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Gathering results\n",
    "To gather results and make the plots you can use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating ARIs for n-times n-fold:  ['example_ncobras', 'example_cobras']\n",
      "already calculated\n",
      "Calculating average ARIs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating average rank\n",
      "all resulting plots are in \\Users\\nicol\\Documents\\KUL 2020-2021\\thesis\\code\\results\\results\\figures\\example_comparison\n"
     ]
    }
   ],
   "source": [
    "test_names = [test_name_robust, test_name]\n",
    "comparison_name = 'example_comparison'\n",
    "nb_of_cores = 4\n",
    "query_budget = 50\n",
    "# calculate aris of each clustering result\n",
    "calculate_n_times_n_fold_aris_for_testnames(test_names, nb_cores=nb_of_cores)\n",
    "# calculate average ari over all folds per dataset\n",
    "calculate_average_aris(test_names, query_budget)\n",
    "\n",
    "# calculates and stores the average aligned rank for each algorithm and each dataset\n",
    "calculate_and_write_aligned_rank(test_names, comparison_name)\n",
    "\n",
    "# plot the average ari for each dataset\n",
    "plot_average_ARI_per_dataset(comparison_name, test_names, test_names)\n",
    "# plot the overall average ari (over all datasets)\n",
    "plot_overall_average_ARI(comparison_name, test_names, test_names)\n",
    "# plot the average aligned ranks\n",
    "plot_rank_comparison_file(comparison_name, test_names, test_names)\n",
    "\n",
    "print(f\"all resulting plots are in {Path(FIGURE_DIR)/comparison_name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
