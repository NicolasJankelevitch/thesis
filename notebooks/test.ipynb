{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module path of dont_know added\n",
      "module path of testing added\n",
      "imports succeeded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path_dont_know = os.path.abspath(os.path.join('../COBRAS_dont_know'))\n",
    "module_path_testing = os.path.abspath(os.path.join('../COBRAS_testing'))\n",
    "\n",
    "if module_path_dont_know not in sys.path:\n",
    "    sys.path.append(module_path_dont_know)\n",
    "    print(\"module path of dont_know added\")\n",
    "\n",
    "if module_path_testing not in sys.path:\n",
    "    sys.path.append(module_path_testing)\n",
    "    print(\"module path of testing added\")\n",
    "    \n",
    "from before_clustering.generate_folds import generate_folds_for_dataset\n",
    "from clustering_algorithms.kmeans_fixed_representative import KmeansFixedRepresentative\n",
    "from clustering_algorithms.kmeans_plus_fixed_representative import KmeansPlusFixedRepresentative\n",
    "from cobras.cobras import COBRAS\n",
    "from cobras.cobras_logger import COBRASLogger\n",
    "from cobras.querier.labelquerier import LabelQuerier\n",
    "from cobras.querier.weak_querier import WeakQuerier\n",
    "from cobras.super_instances.superinstance_select_representative import SuperInstance_select_representative_Builder\n",
    "from config import FOLD_RESULT_DIR, FIGURE_DIR\n",
    "from evaluate_clusterings.calculate_aligned_rank import calculate_and_write_aligned_rank\n",
    "from evaluate_clusterings.calculate_aris import calculate_n_times_n_fold_aris_for_testnames\n",
    "from evaluate_clusterings.calculate_average_aris import calculate_average_aris\n",
    "from generate_clusterings.clustering_task import make_n_run_10_fold_cross_validation\n",
    "from heuristics.select_super_instance_heuristics import *\n",
    "from heuristics.splitlevel_estimation_strategy import *\n",
    "from pathlib import Path\n",
    "from present_results.plot_aligned_rank import plot_rank_comparison_file\n",
    "from present_results.plot_aris import plot_average_ARI_per_dataset\n",
    "from present_results.plot_aris import plot_overall_average_ARI\n",
    "from present_results.plot_query_reuse import calculate_and_plot_query_reuse\n",
    "from present_results.plot_query_reuse_per_dataset import calculate_and_plot_query_reuse_per_dataset\n",
    "from run_locally.run_tests import run_clustering_tasks_locally\n",
    "from util.datasets import Dataset\n",
    "\n",
    "print(\"imports succeeded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not Path(FOLD_RESULT_DIR).exists():\n",
    "    generate_folds_for_dataset()\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitstrat = StandardSplitLevelEstimationStrategyAlwayskmeans(SelectMostInstancesHeuristic())\n",
    "clusterer_1 = COBRAS(cobras_plus=True)\n",
    "#querier = LabelQuerier(None,100)\n",
    "querier = WeakQuerier(None, None ,100,'local_nondet')\n",
    "test_name_1 = \"DK_COBRAS+_ML_only\"\n",
    "all_dataset_names = Dataset.get_standard_dataset_names()#[\"iris\"]#\n",
    "clustering_tasks = make_n_run_10_fold_cross_validation(test_name_1, clusterer_1, querier, all_dataset_names, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer_2 = COBRAS(cobras_plus=True, randomforest_pred=True)\n",
    "test_name_2 = \"DK_rf_pred_COBRAS+_ML_only\"\n",
    "clustering_tasks.extend(make_n_run_10_fold_cross_validation(test_name_2, clusterer_2, querier, all_dataset_names, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 630/630 [4:31:59<00:00, 25.90s/it]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "run_clustering_tasks_locally(clustering_tasks,4)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/630 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating ARIs for n-times n-fold:  ['DK_COBRAS+_ML_only', 'DK_rf_pred_COBRAS+_ML_only']\n",
      "running with 4 cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 630/630 [03:18<00:00,  3.18it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating average ARIs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:10<00:00,  5.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating average rank\n",
      "all resulting plots are in \\Users\\nicol\\Documents\\KUL 2020-2021\\thesis\\code\\results\\results\\figures\\DK_COBRAS+_ML_only_vs_rf_pred\n"
     ]
    }
   ],
   "source": [
    "test_names = [test_name_1,test_name_2]#test_name_1,test_name_6,\n",
    "comparison_name = 'DK_COBRAS+_ML_only_vs_rf_pred'\n",
    "nb_of_cores = 4\n",
    "query_budget = 100\n",
    "\n",
    "#print(clusterer_1.logger.nr_reused_constraints)\n",
    "\n",
    "calculate_n_times_n_fold_aris_for_testnames(test_names, nb_cores=nb_of_cores)\n",
    "calculate_average_aris(test_names, query_budget)\n",
    "calculate_and_write_aligned_rank(test_names,comparison_name)\n",
    "\n",
    "plot_average_ARI_per_dataset(comparison_name, test_names, test_names)\n",
    "plot_overall_average_ARI(comparison_name, test_names, test_names)\n",
    "plot_rank_comparison_file(comparison_name, test_names, test_names)\n",
    "\n",
    "#calculate_and_plot_query_reuse(comparison_name, test_names)\n",
    "#calculate_and_plot_query_reuse_per_dataset(comparison_name, test_names)\n",
    "\n",
    "print(f\"all resulting plots are in {Path(FIGURE_DIR)/comparison_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
